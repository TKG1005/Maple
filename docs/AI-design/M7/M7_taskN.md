ネットワーク拡張タスク実装ガイド (N-1 ～ N-3)
MapleプロジェクトM7における「ネットワーク構造拡張」タスク (N-1, N-2, N-3) の実装手順を示します。これらのタスクでは、エージェントのニューラルネットワークを順次強化し、モデルの表現力や履歴（過去状態）への対応力を高めることが目的です
。
具体的には、以下の3つの要素について実装を行います：
N-1: 全結合ニューラルネットワーク (MLP) の2層化
N-2: LSTM（長短期記憶）層の追加
N-3: Attention（注意機構）の試験的導入

各ステップでは「なぜそれを行うか（目的）」を明確にし、変更対象のファイル、受け入れ基準、テスト方法、および比較対象・比較方法を示します。強化学習やニューラルネットワークに不慣れな実装者でも理解しやすいよう、専門用語はできるだけ平易な言葉で説明します。また、比較には適切な既存モデル（例：1層のシンプルなネットワーク）を用い、学習ステップ数や評価指標を揃えて効果を検証します。

N-1: MLP 2層化 (全結合ネットワークの多層化)
目的 (Why): 現在のエージェントのネットワークは層が浅く（※隠れ層が1層）、モデルの表現力不足が懸念されています。先行研究では2層のMLP（Multi-Layer Perceptron、多層パーセプトロン）によって高速な性能向上が達成された例があり、モデル容量を増やすことでより複雑な戦術パターンを学習できるようにする狙いがあります。そこで、ネットワークを2層の全結合構造に拡張し、中間表現の次元数を増やすことで学習性能の向上を図ります。 
実装対象ファイル (Target File): 
agents/networks.pyエージェントのニューラルネットワーク（ポリシーネットワークや価値ネットワーク）の構造定義を担うファイルです。ここでネットワーク層を追加・変更します。 

適合条件 (Acceptance Criteria):　
ネットワークの全結合層が現在の1層から**2層（隠れ層が2つ）**に拡張されていること。具体的には、例えば入力から出力への変換が128 → 256 → 128のように中間に256ユニット程度の隠れ層を追加した構成に変更されている。
既存モデルとの互換性は不要です。ネットワーク2層化後も学習が正常に進行すること。短いステップ数（例：10,000ステップ程度）の学習を実行し、学習曲線に異常がない（発散しない、損失がNaNにならない等）ことを確認します。

テスト方法 (How to Test):　
ユニットテスト/静的検証: 新たに2層化したネットワークで順伝播 (forward) が期待通り動くか確認します。可能であれば既存の単体テストを拡充し、入力テンソルに対する出力形状が正しいことを確認します。

短時間学習の実行: 
コマンドラインで python train/quick_run.py --steps 10000 --config config/m7.yaml を実行し、約1万ステップの自己対戦学習を行います。学習中および学習後に、TensorBoardのスカラー（例えば平均エピソード報酬や勝率）やログ出力を確認し、以前の1層モデルと比べて学習が安定して進んでいるかを見ます。学習過程で発散がないこと、最終的な報酬が改善傾向にあることが望ましい結果です。
旧モデルとの比較: 同じ条件・ステップ数で**旧構成のネットワーク（1層MLP）**でも学習を行い、TensorBoard上で報酬や勝率の曲線を比較します。2層化によって学習スピードの向上や最終性能の差異が見られるかを分析します（大きな差がない場合も、モデル容量増加による過学習の兆候がないか確認します）。

比較対象 (Baseline Model): 
現行の1層MLP構成のネットワーク（変更前のシンプルな全結合ニューラルネット）。このモデルをベースラインとして、2層化後の性能と学習挙動を評価します。 

比較方法 (Comparison): 
上記の短時間学習実験において、学習曲線（例: 平均エピソード報酬や勝率の推移）を比較します。例えば、同じ10kステップ学習後の平均報酬や勝率を定量的に比較し、2層MLPにすることで初期の学習速度が上がっているか、最終的なエージェント性能（勝率など）が向上しているかを評価します。結果はグラフや数値で記録し、効果を検証します。


N-2: LSTMヘッダ追加 (履歴情報の活用)
目的 (Why): ポケモン対戦環境は部分観測の要素があり、ターンごとの状態遷移や過去の行動履歴を活かすことで、より賢い判断が可能になります。しかし現状のエージェントは直近の観測しか使えず、長期的な文脈を考慮できていません。そこで、過去情報を内部状態に蓄えることができるLSTM (Long Short-Term Memory) 層をネットワークに組み込み、エージェントが過去のターンの情報も踏まえて行動できるようにします。LSTMは再帰型のニューラルネットワークで、直前の隠れ状態を保持しつつ入力を処理できるため、「これまでどんな技を使ったか」「相手が直前に何をしたか」といった履歴を考慮した戦略が可能になります。 
実装対象ファイル (Target File): agents/networks.py
基本のネットワーク構造にLSTMを組み込む変更を行います。必要に応じてagents/observation.pyやutils/obs_stacker.py（ObsStackerクラスが存在する場合）など、観測をどのようにネットワークに供給するかを管理する部分も併せて修正します。 

適合条件 (Acceptance Criteria):
ネットワークの入力部に1層のLSTM層（隠れ状態サイズ128程度）が追加されていること。具体的には、従来は直近の状態を直接全結合層に入力していましたが、変更後はまずLSTMが過去の観測系列を受け取り、その最終出力（隠れ状態）を後段の全結合層に渡す構造になっていること。
履歴情報が供給されていることの検証: LSTMには単一の現在観測だけでなく、一連の観測データが渡されている必要があります。Maple環境ではObsStackerという仕組みで直近数ターン分の状態をスタックしている可能性がありますが、その履歴情報をLSTMに順次入力できているか確認します。例えば、直近$k$ステップ分の観測を時系列データとしてLSTMに入力し、LSTMの出力を次の層に渡す実装になっていることが適合条件です。LSTM追加によってネットワークの勾配計算や学習に問題が発生しないこと。勾配の爆発/消失への対処（勾配クリッピング等）が必要であれば取り入れます。また、LSTMの隠れ状態の初期化やシーケンスの切り分け（エピソード切れ目で隠れ状態リセット等）が正しく実装されていること。オプションとしての実装であること。LSTMヘッダは必要に応じて有効/無効を切り替え可能な設計にします（例えば設定ファイルや引数でLSTMを使うか否か選べるようにする）。これにより、比較実験やAblation（要素検証）が容易になります。

テスト方法 (How to Test):
シーケンス入力テスト: LSTM部分が正しく過去の系列データを処理できるか単体テストします。例えば、疑似的に連続する観測ベクトルを用意し、LSTMに順送りしたときに隠れ状態が更新され、期待される次元の出力が得られるかを確認します。特にObsStacker経由で与える場合は、スタックされた観測を一度に渡す実装なのか、一歩ずつLSTMに入力するのか設計によって異なるため、その挙動を確認します。
短時間学習での動作確認: LSTM有効時と無効時でそれぞれ quick_run.py を実行し、例えば5000～10000ステップ程度学習させます。学習中にエラーが発生しないこと、収束が乱れないことを確認します。可能であれば部分観測下で有利になるシナリオ（例：相手のポケモンを交代しつつ戦う状況など、履歴が物を言うケース）を作り、LSTMありの場合にスムーズに対処できているかを観察します。
性能比較: 一定ステップ学習後のエージェント性能を評価し、LSTMなし（通常の2層MLP）の場合と比較します。評価指標として勝率や平均報酬の他、行動選択の多様性や戦略パターンの違いにも注目します。LSTMありのエージェントが過去の状態を考慮した行動（例えば無駄な連続交代を避ける等）をとれているか、定性的なプレイログの確認も有益です。
比較対象 (Baseline Model): LSTMを追加していない通常のフィードフォワードネットワーク（N-1で実装した2層MLP構成）。このベースラインと比べることで、履歴対応力を持たせた効果を検証します。 比較方法 (Comparison): LSTMあり・なしでそれぞれ同じ条件・エピソード数で学習を行い、学習曲線や最終性能を比較します。例えば、各モデルを10万ステップずつ学習させた後の勝率を比較したり、学習中の平均報酬の立ち上がり方に差が出るかを分析します。部分観測下での挙動に差が現れることが期待されるため、必要に応じてエピソードのリプレイやログを調べ、LSTMが有効に作用している場面を確認します。結果の比較により、LSTM追加のメリット（またはトレードオフ：例えば学習の安定性や計算コストへの影響）を明らかにします。

N-3: Attention機構試験導入 (自己注意の活用)
目的 (Why): 最新の深層強化学習では自己注意機構 (self-attention) を用いて、重要な特徴に動的に重み付けを行い効果的な表現学習をする手法が注目されています。そこで本タスクでは、試験的にAttention層をネットワークに組み込み、その効果をベンチマークします。具体的には、ポケモン対戦における自分のポケモン側特徴と相手ポケモン側特徴それぞれに対し、マルチヘッドの自己注意機構を適用し、どの要素（例えばどのポケモンやステータス）が重要かをネットワーク自身に学習させます。これにより、固定の特徴量変換では捉えきれない相互関係（例：ある自分のポケモンと相手の特定ポケモンとの組み合わせ効果）を捉えることを期待しています。 
実装対象ファイル (Target File): agents/attention.py
Attention機構に関するクラスや関数を実装・追加するファイルです。PyTorchのnn.MultiheadAttentionなどを利用しても構いませんし、自前でシンプルな自己注意層を実装しても構いません。併せて、既存のネットワーク定義（agents/networks.pyなど）からこのAttention機構を呼び出せるように改修します。 

適合条件 (Acceptance Criteria):
マルチヘッドAttention層が実装されていること。少なくともキー・クエリ・バリューからスコアを計算し重み付け和をとる基本的な自己注意メカニズムが含まれていることが必要です。ヘッド数は複数（例：4や8）設け、それぞれ独立に注意重みを学習できるようにします。自分側特徴量群・相手側特徴量群それぞれに対してAttention層を適用し、その出力を後段のネットワーク（例えば全結合層やLSTMの後）に統合していること。例えば、自分チームのポケモンに関する入力ベクトル集合と相手チームに関する入力ベクトル集合を別々に自己注意にかけ、それらを結合して最終的な意思決定用の特徴表現とする構成を想定しています。
このAttention機構の導入があくまで試験的であり、既存のネットワークに対してオプション扱いになっていること。すなわち、Attentionを組み込んだネットワークは実験的に使用し、本流の学習では従来構造も選択できる設計になっていること（設定でオン/オフ可能）。コード上でも大きなリファクタリングではなくフック的に実装し、容易に取り外しや改良ができる形が望ましいです。
実装後、ベンチマークテストが行われていること。ベンチマークとは、Attentionあり・なしでの性能比較や、計算コストの測定などを指します。学習自体は長時間行わずとも、一定エピソードでの報酬・勝率を比較し有効性の手がかりを掴むこと、またネットワークの計算時間やメモリ使用量に過度の負荷が無いことを確認します。

テスト方法 (How to Test):
単体動作確認: Attention層に対し、架空の入力テンソルを使って前後のサイズが期待通りか確認します。例えば、特徴ベクトルの集合（自分側や相手側のポケモンごとのベクトル群）を入力し、Attention層を通した出力の形状・値に不備がないかテストします。マルチヘッドの場合はヘッドの結合処理まで含めて検証します。
統合テスト（前向き伝播スルー）: 新しいAttention付きネットワーク全体で、サンプル観測を入力した際にエラーなくforwardが通るか確認します。LSTM等とも共存させる場合、シーケンス長やテンソル形状に齟齬がないかもチェックします。
ベンチマーク学習: Attentionを有効にした場合と無効の場合で、それぞれ数千～1万ステップ程度の学習を実行し、報酬の得られ方や勝率の変化を比較します。短時間の学習結果で劇的な差が出るとは限りませんが、学習の安定性（損失の発散有無）や初期収束速度に違いがないか確認します。また、各ステップの計算時間を計測し、Attention導入によるオーバーヘッドが許容範囲かを評価します。
注意重みの観察 (任意): 可能であれば、学習後のモデルから注意の重みを取り出し、どの特徴に高い重みが割り当てられているかを解析します。これにより、エージェントがどの要素を重視しているかが分かり、Attention機構が意味のある視点を提供しているか定性的に判断できます。
比較対象 (Baseline Model): Attention未導入の通常ネットワーク（N-1やN-2までで構築したもの。例えば2層MLP+LSTMなどからAttention部分を除いた構成）。現状の基本モデルとの間で性能や計算コストを比較します。 比較方法 (Comparison): 同一条件での学習および評価を行い、Attentionの有無で結果を比較します。例えば、5000ステップ学習後の平均報酬や勝率を両モデルで算出し比べる、あるいは学習中のスカラーをプロットして重ねてみて収束傾向に差が出ていないか確認します。加えて、GPU使用率や1エピソード当たりの推論時間も計測し、実運用上問題ない範囲か検証します。Attention導入により顕著な性能向上が見られれば今後の標準構成への組み込みを検討し、効果が薄い場合や計算コスト増大が大きい場合は引き続き改善を検討する材料とします。

以上の手順に従い、ネットワーク拡張の各ステップ(N-1～N-3)を順に実装・検証してください。重要なのは、各ステップが単独で完結するようにすること（一度に複数の変更を加えず、ステップごとに目的と成果を明確にする）です。その上で、徐々にモデルの表現力と学習能力を強化し、最終的にエージェントの性能向上に寄与することを確認していきましょう
。
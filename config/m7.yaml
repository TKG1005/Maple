episodes: 10000
lr: 0.002
batch_size: 512
buffer_capacity: 1000
gamma: 0.997
gae_lambda: 0.95
clip_range: 0.2
value_coef: 0.6
entropy_coef: 0.02
ppo_epochs: 4
algorithm: ppo
reward: composite
reward_config: config/reward.yaml

# Network architecture configuration for M7 tasks
network:
  type: "basic"  # Options: basic, lstm, attention
  hidden_size: 128
  use_2layer: true
  use_lstm: false
  use_attention: false
  lstm_hidden_size: 128
  attention_heads: 4
  attention_dropout: 0.1